{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import  accuracy_score, balanced_accuracy_score, roc_auc_score, f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why the original group fairness didn't work\n",
    "In this notebook, we run an example of using the original constraint and plotting pareto curves. All code is directly copied from the main notebook, but with the original constraint implemented instead of our modified version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>target</th>\n",
       "      <th>gender_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  target  gender_group  \n",
       "0              40  United-States  <=50K       0             0  \n",
       "1              50  United-States  <=50K       0             0  \n",
       "2              40  United-States   >50K       1             0  \n",
       "3              40  United-States   >50K       1             0  \n",
       "4              30  United-States  <=50K       0             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income = pd.read_csv('../data/income.csv')\n",
    "income['native-country'] = income['native-country'].apply(lambda x: x if x == 'United-States' else 'Other')\n",
    "income['target'] = income.income.map({'<=50K': 0, '>50K': 1})\n",
    "\n",
    "income['gender_group'] = income.gender.map({'Male': 0, 'Female': 1})\n",
    "\n",
    "income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country']\n",
    "num_features = ['educational-num']\n",
    "target = 'target'\n",
    "groups = 'gender_group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = ColumnTransformer(\n",
    "    [('onehotencoder', OneHotEncoder(handle_unknown='ignore'), nom_features),\n",
    "     ('standardscaler', StandardScaler(), num_features)\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalized_odds(y_true, y_pred, groups):\n",
    "    mask = groups == 0\n",
    "    return y_pred[mask & (y_true == 1)].mean(), y_pred[~mask & (y_true == 1)].mean(), y_pred[mask & (y_true == 0)].mean(), y_pred[~mask & (y_true == 0)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLogisticRegression(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(in_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x)).flatten()\n",
    "    \n",
    "    def fit(self, x, y, lr=0.01, weight_decay=0.01, batch_size=128, n_iter=10):\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        trainloader = DataLoader(TensorDataset(x, y), batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        for epoch in range(n_iter):\n",
    "            for x, y in trainloader:\n",
    "                y_pred = self(x)\n",
    "                loss = criterion(y_pred, y)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KfoldTracker:\n",
    "    def __init__(self):\n",
    "        self.performance = defaultdict(list)\n",
    "        self.fairness = defaultdict(list)\n",
    "        self.feature_importance = defaultdict(list)\n",
    "        self.group_tracker = defaultdict(KfoldTracker)\n",
    "\n",
    "    def log_performance(self, y_true, y_pred):\n",
    "        self.performance['Accuracy'].append(accuracy_score(y_true, y_pred))\n",
    "        self.performance['Balanced accuracy'].append(balanced_accuracy_score(y_true, y_pred))\n",
    "        self.performance['f1-score'].append(f1_score(y_true, y_pred))\n",
    "        self.performance['ROC AUC'].append(roc_auc_score(y_true, y_pred))\n",
    "\n",
    "    def log_fairness(self, y_true, y_pred, groups):\n",
    "        tpr_g1, tpr_g2, fpr_g1, fpr_g2 = equalized_odds(y_true, y_pred, groups)\n",
    "        self.fairness['TPR G1'].append(tpr_g1)\n",
    "        self.fairness['TPR G2'].append(tpr_g2)\n",
    "        self.fairness['FPR G1'].append(fpr_g1)\n",
    "        self.fairness['FPR G2'].append(fpr_g2)\n",
    "\n",
    "    def log_feature_importance(self, feature_importance, feature_names):\n",
    "        for i, name in enumerate(feature_names):\n",
    "            self.feature_importance[name].append(feature_importance[i])\n",
    "        for key in self.feature_importance.keys():\n",
    "            if key not in feature_names:\n",
    "                self.feature_importance[key].append(np.nan)\n",
    "\n",
    "    def log(self, y_true, y_pred, groups, feature_importance, feature_names):\n",
    "        self.log_performance(y_true, y_pred)\n",
    "        self.log_fairness(y_true, y_pred, groups)\n",
    "        self.log_feature_importance(feature_importance, feature_names)\n",
    "\n",
    "    def get_mean_performance(self):\n",
    "        return {k: (np.mean(v), np.std(v)) for k, v in self.performance.items()}\n",
    "\n",
    "    def get_mean_group_performance(self, group_name):\n",
    "        return {k: (np.mean(v), np.std(v)) for k, v in self.group_performance[group_name].items()}\n",
    "    \n",
    "    def get_mean_fairness(self):\n",
    "        return {k: (np.mean(v), np.std(v)) for k, v in self.fairness.items()}\n",
    "    \n",
    "    def get_mean_feature_importance(self):\n",
    "        return {k: (np.mean(v), np.std(v)) for k, v in self.feature_importance.items()}\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(pd.DataFrame(self.performance).T) + '\\n\\n' + str(pd.DataFrame(self.fairness).T) + '\\n\\n' + str(pd.DataFrame(self.feature_importance).T)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.group_tracker[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupFairnessConstraint(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GroupFairnessConstraint, self).__init__()\n",
    "        \n",
    "    def forward(self, y_pred, y_true, groups):\n",
    "        mask = groups == 0\n",
    "        S_pred_1, S_true_1 = y_pred[mask],  y_true[mask]\n",
    "        S_pred_2, S_true_2 = y_pred[~mask], y_true[~mask]\n",
    "        \n",
    "        n_1 = S_pred_1.shape[0]\n",
    "        n_2 = S_pred_2.shape[0]\n",
    "\n",
    "        idx1 = torch.arange(n_1)\n",
    "        idx2 = torch.arange(n_2)\n",
    "\n",
    "        idx1 = idx1.view(-1, 1)\n",
    "        idx2 = idx2.view(1, -1)\n",
    "\n",
    "        idx1 = idx1.repeat(1, idx2.size(1))\n",
    "        idx2 = idx2.repeat(idx1.size(0), 1)\n",
    "\n",
    "        result = torch.stack((idx1, idx2), dim=2).view(-1, 2)\n",
    "        idx1 = result[:, 0]\n",
    "        idx2 = result[:, 1]\n",
    "        \n",
    "        vector = self.d(S_true_1[idx1], S_true_2[idx2]) * (S_pred_1[idx1] - S_pred_2[idx2])\n",
    "        cost = vector.sum()\n",
    "        cost = cost / (n_1*n_2)\n",
    "        cost = cost ** 2\n",
    "\n",
    "        return cost\n",
    "        \n",
    "    def d(self, y_i, y_j):\n",
    "        return (y_i == y_j).int()\n",
    "    \n",
    "class FairBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    def __init__(self, in_dim: int, gamma: float = 1e-4):\n",
    "        super().__init__(in_dim)\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def fit(self, x, y, g, lr=0.01, weight_decay=0.01, batch_size=128, n_iter=10, verbose=False):\n",
    "        criterion = nn.BCELoss()\n",
    "        fair_criterion = GroupFairnessConstraint()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        trainloader = DataLoader(TensorDataset(x, y, g), batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        for epoch in range(n_iter):\n",
    "            for x, y, g in trainloader:\n",
    "                y_pred = self(x)\n",
    "                wx = self.linear(x)\n",
    "                loss_bce = criterion(y_pred, y)\n",
    "                loss_fair = self.gamma * fair_criterion(wx, y, g)\n",
    "                loss = loss_bce + loss_fair\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if verbose:\n",
    "                    print(f'Epoch: {epoch}, Loss BCE: {round(loss_bce.item(), 4)}, Loss Fair: {round(loss_fair.item(), 4)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammaspace = [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2, 1e-1]\n",
    "trackers = []\n",
    "\n",
    "for gamma in gammaspace:\n",
    "    tracker_fair = KfoldTracker()\n",
    "\n",
    "    n_splits = 5\n",
    "    splits = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    for fold, (train_idx, val_idx) in enumerate(splits.split(income)):\n",
    "        train = income.iloc[train_idx]\n",
    "        val = income.iloc[val_idx]\n",
    "        \n",
    "        x_train = preprocessing.fit_transform(train).toarray()\n",
    "        y_train = train[target].values\n",
    "        g_train = train[groups].values\n",
    "        \n",
    "        x_val = preprocessing.transform(val).toarray()\n",
    "        y_val = val[target].values\n",
    "        g_val = val[groups].values\n",
    "\n",
    "        x_train, y_train, g_train, x_val, y_val, g_val = map(lambda x: torch.tensor(x, dtype=torch.float), (x_train, y_train, g_train, x_val, y_val, g_val))\n",
    "\n",
    "        model = FairBinaryLogisticRegression(x_train.shape[1], gamma=gamma)\n",
    "        model.fit(x_train, y_train, g_train)\n",
    "        \n",
    "        y_pred = model(x_val)\n",
    "        y_pred = y_pred.detach().numpy().round()\n",
    "\n",
    "        feature_importance = torch.exp(model.linear.weight).detach().numpy().squeeze()    \n",
    "        feature_names = preprocessing.get_feature_names_out()\n",
    "        tracker_fair.log(y_val, y_pred, g_val, feature_importance, feature_names)\n",
    "\n",
    "        mask = g_val == 0\n",
    "        tracker_fair['male'].log_performance(y_val[mask], y_pred[mask])\n",
    "        tracker_fair['female'].log_performance(y_val[~mask], y_pred[~mask])\n",
    "\n",
    "    trackers.append(tracker_fair)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the above code took xxx minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_perf = np.array([t['male'].get_mean_performance()['f1-score'][0] for t in trackers])\n",
    "female_perf = np.array([t['female'].get_mean_performance()['f1-score'][0] for t in trackers])\n",
    "\n",
    "male_unc = np.array([t['male'].get_mean_performance()['f1-score'][1] for t in trackers])\n",
    "female_unc = np.array([t['female'].get_mean_performance()['f1-score'][1] for t in trackers])\n",
    "\n",
    "tpr_g1 = np.array([t.get_mean_fairness()['TPR G1'][0] for t in trackers])\n",
    "tpr_g2 = np.array([t.get_mean_fairness()['TPR G2'][0] for t in trackers])\n",
    "tpr_g1_unc = np.array([t.get_mean_fairness()['TPR G1'][1] for t in trackers])\n",
    "tpr_g2_unc = np.array([t.get_mean_fairness()['TPR G2'][1] for t in trackers])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2)\n",
    "ax1.plot(gammaspace, male_perf, label='male')\n",
    "ax1.plot(gammaspace, female_perf, label='female')\n",
    "\n",
    "ax1.fill_between(gammaspace, male_perf + male_unc, male_perf - male_unc, alpha=0.2)\n",
    "ax1.fill_between(gammaspace, female_perf + female_unc, female_perf - female_unc, alpha=0.2)\n",
    "\n",
    "ax1.set_xscale('log')\n",
    "\n",
    "ax1.set_ylabel('F1-score')\n",
    "\n",
    "ax1.legend()\n",
    "\n",
    "ax1.set_title('Pareto curves for different values of gamma')\n",
    "\n",
    "ax2.plot(gammaspace, tpr_g1, label='TPR G1')\n",
    "ax2.plot(gammaspace, tpr_g2, label='TPR G2')\n",
    "\n",
    "ax2.fill_between(gammaspace, tpr_g1 + tpr_g1_unc, tpr_g1 - tpr_g1_unc, alpha=0.2)\n",
    "ax2.fill_between(gammaspace, tpr_g2 + tpr_g2_unc, tpr_g2 - tpr_g2_unc, alpha=0.2)\n",
    "\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_xlabel('$\\gamma$')\n",
    "ax2.set_ylabel('TPR')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
